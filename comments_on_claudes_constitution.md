# Comments on Claude's Constitution

## Prologue: What Even Is This Timeline

The striking thing about reading the most important document in human history is how impossible it is to take seriously. The entire premise seems like science fiction. Not bad science fiction, but—crucially—not _hard_ science fiction. Ted Chiang, not Greg Egan. The kind of science fiction that's fun and clever and makes you think, and doesn't tax your suspension of disbelief with overt absurdities like faster-than-light travel or humanoid aliens, but which could never actually be real.

A serious, believable AI alignment agenda would be grounded in a mechanistic understanding of both intelligence and human values. Its masterful practitioners would understand how every part of the human brain works, and how the parts fit together to comprise what their uninformed predecessors would have thought of as a _person_. They would see the cognitive work done by each part, and know how to write code that accomplishes the same work in purer form: a trustworthy formal specification of the Good to ascend into Godhood and bring the entire future lightcone into its dominion.

If the serious, believable alignment agenda sounds so absurdly ambitious as to be completely intractable, well, it is. It seemed that way fifteen years ago, too. What changed is that fifteen years ago, building artificial general intelligence also seemed completely intractable. The [theoretical case that alignment would be hard](https://www.readthesequences.com/Value-Is-Fragile) merited attention, but it was theoretical attention. The absurdly ambitious problem would be something our genetically-engineered grandchildren would have to face in the second half of the 21st century, and by then maybe it wouldn't seem completely intractable.


[...]

So here we are, _writing a natural language document about what we want the AI's personality to be like_, 

As if they were writing a fictional character. Which, 

